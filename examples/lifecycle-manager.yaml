apiVersion: v1
kind: Namespace
metadata:
  name: lifecycle-manager
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: lifecycle-manager
  namespace: lifecycle-manager
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: lifecycle-manager
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "patch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods/eviction"]
  verbs: ["create"]
- apiGroups: ["extensions", "apps"]
  resources: ["daemonsets"]
  verbs: ["get"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["get", "list", "create"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: lifecycle-manager
subjects:
- kind: ServiceAccount
  name: lifecycle-manager
  namespace: lifecycle-manager
roleRef:
  kind: ClusterRole
  name: lifecycle-manager
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: lifecycle-manager
  namespace: lifecycle-manager
  labels:
    app: lifecycle-manager
spec:
  replicas: 1
  selector:
    matchLabels:
      app: lifecycle-manager
  template:
    metadata:
      labels:
        app: lifecycle-manager
    spec:
      serviceAccountName: lifecycle-manager
      containers:
        - image: keikoproj/lifecycle-manager:latest
          imagePullPolicy: "Always"
          name: lifecycle-manager
          resources:
            limits:
              # tested against surges of up to 100 nodes terminating, you may want more/less memory
              # depending on your cluster behavior
              memory: 2048Mi
            requests:
              cpu: 100m
              memory: 256Mi
          command:
            - /bin/lifecycle-manager
            - serve
            - --queue-name=lifecycle-manager-queue
            - --region=us-west-2